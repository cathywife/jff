https://www.elastic.co/guide/en/elasticsearch/reference/2.1/index.html

Getting Started
===============

Cluster health:     curl -s "$ES/_cat/health?v"
Node status:        curl -s "$ES/_cat/nodes?v"
List all indices:   curl -s "$ES/_cat/indices?v"

Create an index:    curl -s -XPUT "$ES/customer?pretty" -d '{
                        "settings": {
                            "number_of_shards": 5,
                            "number_of_replicas": 1
                        },
                        "mappings": {
                            "type1" : {
                                ...
                            }
                        },
                        "warmers": {
                            ...
                        },
                        "aliases": {
                        }
                    }'
Get index info:     curl -s "$ES/customer?pretty"
Indices exists:     curl -s -XHEAD -i "$ES/customer"
Delete an index:    curl -s -XDELETE "$ES/customer?pretty"

Index a document:   curl -s -XPUT "$ES/customer/external/1?pretty" -d '{ "name": "John Doe" }'
                    curl -s -XPOST "$ES/customer/external?pretty"  -d '{ "name": "Jane Doe" }'
        // how to disable version?
        // how to drop not update duplicate document by id?
Get a document:     curl -s "$ES/customer/external/1?pretty"
Delete a document:  curl -s -XDELETE "$ES/customer/external/1?pretty"

Batch Processing:   curl -s -XPOST "$ES/customer/external/_bulk?pretty" -d '
                    {"index": {"_id": "1"}}
                    {"name": "John Doe"}
                    {"index": {"_id": "2"}}
                    {"name": "Jane Doe"}
                    '
        Endpoints: /_bulk, /{index}/_bulk, /{index}/{type}/_bulk;
        Make sure the HTTP client doesn't send HTTP chunks, as this will slow things down;
        Supported directives: index, create, update, delete;
        NOTICE: must be line by line with LF.
        // how to dismiss verbose reponse??: use response filtering

Search API:         curl -s "$ES/customer/_search?q=*&pretty"
                    curl -s -XPOST "$ES/customer/_search?pretty" -d '
                    {
                        "query": { "match_all": {} }
                    }'


Setup
=====

Run:    bin/elasticsearch -d -p path/to/pid -Des.index.refresh_interval=5s --node-name=my-node

        ES_JAVA_OPTS=...
        ES_HEAP_SIZE=31g        # set both -Xms and -Xmx

        increase open file limit:
            ulimit -n: 32k or even 64k

            -Des.max-open-files=true    # print max file descriptors
            or: curl -s "$ES/_nodes/stats/process?pretty" | grep file_desc

        increase VMA count:
            sysctl -w vm.max_map_count=262144   # or set in /etc/sysctl.conf

        turn off swap, three options:
            * sudo swapoff -a     # or set in /etc/fstab
            * sysctl -w vm.swappiness=1     # since linux kernel >3.5-rc set to
                                            # 0 will cause the OOM killer kill
                                            # the process instead of allowing swapping.
            * bootstrap.mlockall: true in config/elasticsearch.yml
                curl -s "$ES/_nodes/process?pretty" | grep mlockall
                ulimit -l unlimited;
                bin/elasticsearch -Djna.tmpdir=/path/to/new/dir if default /tmp is mounted with "noexec" option.

Backup:

    ES >= 1.0: use snapshots
    ES < 1.0:
      * disalbe index flushing:
        curl -s -XPUT "$ES/_all/_settings" -d '{"index": {"translog.disable_flush": "true"}}'
      * disable reallocation:
        curl -s -XPUT "$ES/_cluster/settings" -d '{"transient": {"cluster.routing.allocation.enable": "none"}}'
      * backup data path
      * enable index flushing:
        curl .... "false"
      * enable allocation:
        curl ...  "all"

Rolling upgrade:

    * disable shard allocation:
        curl -s -XPUT "$ES/_cluster/settings" -d '{"transient": {"cluster.routing.allocation.enable": "none"}}'
    * stop non-essential indexing and perform a synced flush:
        curl -s -XPOST"$ES/_flush/synced"
    * stop the node
    * start the upgraded node, check "$ES/_cat/nodes?v"
    * reenable shard allocation:
        curl -s -XPUT "$ES/_cluster/settings" -d '{"transient": {"cluster.routing.allocation.enable": "all"}}'
    * wait for the node to recover:
        curl -s "$ES/_cat/health"       # "status" changes from yellow to green if there are more upgraded nodes for replica
                                        # else check "init" and "relo" columns, should be zero
        curl -s "$ES/_cat/recovery?v"   # check the recovery process
    * go to next node

Full restart upgrade:

    * disable shard allocation, notice its "persistent", not "transient"!!!
        curl -s -XPUT "$ES/_cluster/settings" -d '{"persistent": {"cluster.routing.allocation.enable": "none"}}'
    * perform a synced flush:
        curl -s -XPOST "$ES/_flush/synced"
    * shutdown and upgrade all nodes
    * start dedicated master nodes first, check "/_cat/health" and "/_cat/nodes"
      to make sure election is done and all nodes join the cluster
            dedicated master:   node.master=true node.data=false
            data node:          node.master=false node.data=true
            gateway node:       node.master=false node.data=false
    * wait until all nodes join the cluster
    * reenable allocation:
        curl -s -XPUT "$ES/_cluster/settings" -d '{"persistent": {"cluster.routing.allocation.enable": "all"}}'
    * monitor progress with "/_cat/health" and "/_cat/recovery", until "status" in "/_cat/health" becomes green


Breaking changes
================

v2.1:
    * updates now detect_noop=true by default
    * the Optimiize API deprecated, use the new Force Merge API
v2.0:
    * merge scheduler is no longer pluggable
    * multiple path.data stripping is no longer supported
    * async replication for CRUD operations is removed, it's now synchronous
      only, so you need more client processes to send more requests in parallel


API Conventions
===============

Multiple indices:
    * index1,index2,index3
    * _all
    * index*,+test*,-test3

    query string parameters: ignore_unavailable, allow_no_indices, expand_wildcards

    date math support in index names:  <static_name{date_math_expr{date_format|time_zone}}>

Response filtering:
    * &filter_path=path1,path2,...

URL-based access control:
    * config.yml:  rest.action.multi.allow_explicit_index: alse


Document APIs
=============

Automatic Index Creation:
    * action.auto_create_index: [true] | false, +aaa*,-bbb*
    * index.mapper.dynamic: [true] | false

Operation Type:
    * curl -s -XPUT "$ES/twitter/tweet/1?op_type=create' -d '...'
    * curl -s -XPUT "$ES/twitter/tweet/1/_create" -d '...'

Routing:
    * curl -s -XPOST "$ES/twitter/tweet?routing=some_value" -d '...'


Indices APIs
============

Bulk indexing optimization:

    * curl -XPUT "$ES/test/_settings" -d '{ "index": { "refresh_interval":  "-1" }}'
      then set "refresh_interval": "1s" after bulk indexing.
      then: curl -XPOST "$ES/test/_forcemerge?max_num_segments=5"
    * or start the index without any replicas, and increase replica later.


Index Templates:

    * curl -s -XPUT "$ES/_template/template_1" -d '
      {
          "template": "te*",
          "order": 0,
          "settings": {
              ...
          },
          "mappings": {
              ...
          }
      }'

Indices stats:
    * curl -s "$ES/_stats?pretty"
    * curl -s "$ES/index1,index2/_stats?pretty"

Indices segements:
    * curl -s "$ES/_segments?pretty&verbose=true"
    * curl -s "$ES/index1,index2/_segments?pretty&verbose=true"

Indices recovery:
    * curl -s "$ES/_recovery?pretty&human&detailed=true"
    * curl -s "$ES/index1,index2/_recovery?pretty&human&detailed=true"

Indices shard stores:
    * curl -s "$ES/_shard_stores?pretty"        # &status=green,yellow,red, default is "yellow,red"
    * curl -s "$ES/index1,index2/_shard_stores?pretty"

Clear cache:
    * curl -s "$ES/_cache/clear"        # query=true&fielddata=true&request=true, fields=xxx,yyy
    * curl -s "$ES/index1,index2/_cache/clear"

Flush indices to disk: flush data, clear transaction log, free memory
    * Elasticsearch uses memory heuristics to automatically trigger flush operations
    * curl -s -XPOST "$ES/index1,index2/_flush"

Synced flush:
    * if a shard hasn't received any indexing operation for 5min, a "synced flush" is triggered
    * performs a normal flush, then adds a generated unique marker(sync_id) to all shards
    * to check whether a shard has a marker: curl -s "$ES/index1/_stats/commit?level=shards"
    * perform synced flush: curl -s "$ES/index1/_flush/synced"

Refresh: make all operations performed since last refresh available for search
    * by default a refresh is scheduled periodically
    * curl -s -XPOST "$ES/index1/_refresh"

Force merge:
    * curl -s -XPOST "$ES/index1/_forcemerge"   # max_num_segments=N, only_expunge_deletes=true
    * old name is "/_optimize"

Index upgrade:
    * upgrade to new Lucene index format
    * perform upgrade: curl -s -XPOST "$ES/index1/_upgrade"
    * check upgrade status: curl -s "$ES/index1/_upgrade"   # level=[index]|shard|cluster


cat APIs
========

curl -s "$ES/_cat"      # list all cat commands

common parameters:
    v               verbose
    help            show command help
    h=head1,head2   show only those columns
    bytes=b         turn off human mode

curl -s $ES/_cat/aliases                # show index alias
curl -s $ES/_cat/aliases/{alias}
curl -s $ES/_cat/allocation             # show shard allocation, disk usage
curl -s $ES/_cat/count                  # count document of the entire cluster
curl -s $ES/_cat/count/{index}
curl -s $ES/_cat/fielddata              # how much heap memory is currently being used by fielddata
curl -s $ES/_cat/fielddata/{fields}
curl -s $ES/_cat/health
curl -s $ES/_cat/indices
curl -s $ES/_cat/indices/{index}
curl -s $ES/_cat/master
curl -s $ES/_cat/nodeattrs
curl -s $ES/_cat/nodes                  # !!! explicitly specified columns, by default it shows a few
                                        # https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-nodes.html
curl -s $ES/_cat/pending_tasks
curl -s $ES/_cat/plugins
curl -s $ES/_cat/recovery
curl -s $ES/_cat/recovery/{index}
curl -s $ES/_cat/repositories
curl -s $ES/_cat/segments
curl -s $ES/_cat/segments/{index}
curl -s $ES/_cat/shards
curl -s $ES/_cat/shards/{index}
curl -s $ES/_cat/snapshots
curl -s $ES/_cat/thread_pool            # !!! more thread pools specified by h=xxx


Cluster APIs
============

Node configuration:
    * curl -s "$ES/_nodes"
    * curl -s "$ES/_nodes/nodeA"

Cluster health:
    * curl -s "$ES/_cluster/health?pretty"      # level=[cluster] | indices | shards
    * more parameters: https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html

Cluster state:

